{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93062fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time, sqlite3, warnings\n",
    "from typing import Dict, Any, List\n",
    "import re\n",
    "import easyocr\n",
    "from euriai.langgraph import EuriaiLangGraph\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad406959",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EURI_API_KEY    = os.getenv(\"EURI_API_KEY\")\n",
    "MODEL           = \"gpt-4.1-nano\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6d19783",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR       = \"invoices\" # drectory where invoices stored.\n",
    "DB_PATH         = \"invoice.sqlite\" # Database path\n",
    "PROCESSED_LOG   = \"processed.json\" # Keeps the logs of all the processed file.\n",
    "POLL_SEC        = 5 # it keep on checking invoice folder in every 5 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7480951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(INPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33896352",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function return the all the data from PROCESSED_LOG\n",
    "if PROCESSED_LOG is not exist, then it return empty set\n",
    "if PROCESSED_LOG exist, it return all the data\n",
    "\"\"\"\n",
    "def load_seen() -> set:\n",
    "    if not os.path.exists(PROCESSED_LOG):\n",
    "        return set()\n",
    "    try:\n",
    "        with open(PROCESSED_LOG, 'r', encoding=\"utf-8\") as f:\n",
    "            return set(json.load(f))\n",
    "    except Exception:\n",
    "        return set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb10c075",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "this function write the seen data in PROCESSED_LOG\n",
    "\"\"\"\n",
    "def save_seen(seen: set) -> None:\n",
    "    with open(PROCESSED_LOG, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(sorted(list(seen)), f, ensure_ascii=False, indent=2)\n",
    "\n",
    "seen = load_seen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbf774d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "''''\n",
    "We have to create a function which will create a table inside database. So that file can stored in structured format.\n",
    "'''\n",
    "\n",
    "def ensure_schema():\n",
    "    con = sqlite3.connect(DB_PATH) # Make connection with Database.\n",
    "    cur = con.cursor() # Create cursor. Cursor allows to exceute SQL commands\n",
    "    # Create if missing\n",
    "    cur.execute(\n",
    "        \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS invoices(\n",
    "id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "file_name TEXT,\n",
    "vendor TEXT,\n",
    "number TEXT,\n",
    "date TEXT,\n",
    "total REAL,\n",
    "currency TEXT,\n",
    "raw_json TEXT\n",
    ")\n",
    "\"\"\"\n",
    "    )\n",
    "    cur.execute(\"PRAGMA table_info(invoices);\") # retrieves detailed information about the columns of the table \"invoices\"\n",
    "    cols = {row[1] for row in cur.fetchall()} # This fetch all columns name -- id, file_name, vendor, number, date, total, currency, raw_json\n",
    "    if \"file_name\" not in cols:\n",
    "        cur.execute(\"ALTER TABLE invoices ADD COLUMN file_name TEXT;\")\n",
    "    if \"raw_json\" not in cols:\n",
    "        cur.execute(\"ALTER TABLE invoices ADD COLUMN raw_json TEXT;\")\n",
    "    con.commit()\n",
    "    con.close()\n",
    "ensure_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5925686c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "# Define a variable for easyocr\n",
    "ocr = easyocr.Reader([\"en\"], gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5729d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the LLM\n",
    "\n",
    "clean_graph = EuriaiLangGraph(api_key=EURI_API_KEY, default_model=MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "31f82d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added AI node: CLEAN (model: gpt-4.1-nano)\n",
      "Set entry point: CLEAN\n",
      "Set finish point: CLEAN\n"
     ]
    }
   ],
   "source": [
    "# Creating Node name CLEAN\n",
    "clean_graph.add_ai_node(\n",
    "    \"CLEAN\",\n",
    "    \"\"\"\n",
    "You clean noisy OCR to plain text.\n",
    "- Keep facts.\n",
    "- No guessing.\n",
    "- Keep table rows readable.\n",
    "OCR:\n",
    "{ocr_text}\"\"\"\n",
    ")\n",
    "clean_graph.set_entry_point(\"CLEAN\")\n",
    "clean_graph.set_finish_point(\"CLEAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9cb46216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added AI node: EXTRACT (model: gpt-4.1-nano)\n",
      "Set entry point: EXTRACT\n",
      "Set finish point: EXTRACT\n"
     ]
    }
   ],
   "source": [
    "extract_graph = EuriaiLangGraph(api_key=EURI_API_KEY, default_model=MODEL)\n",
    "extract_graph.add_ai_node(\n",
    "    \"EXTRACT\",\n",
    "    \"\"\"\n",
    "FROM CLEAN_TEXT, return STRICT JSON with keys exactly:\n",
    "vendor, number, date, total, currency,\n",
    "line_items (list of {{description, quantity, unit_price, amount}}).\n",
    "\n",
    "Unknown -> null. Numbers numeric. Dates YYYY-MM-DD if possible.\n",
    "JSON ONLY, no extra text.\n",
    "\n",
    "CLEAN_TEXT:\n",
    "{clean_text}\"\"\"\n",
    ")\n",
    "extract_graph.set_entry_point(\"EXTRACT\")\n",
    "extract_graph.set_finish_point(\"EXTRACT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db74c2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_text(x,*,prefer_key=None):\n",
    "    \"\"\"Return a plain string from various possible structure.\n",
    "    If x is a dict, try prefer_key or common key; else stringify.\n",
    "    \"\"\"\n",
    "    if isinstance(x, str):\n",
    "        return x\n",
    "    if isinstance(x, dict):\n",
    "        if prefer_key and prefer_key in x and isinstance(x[prefer_key], str):\n",
    "            return x[prefer_key]\n",
    "        for k in (\"output\", \"text\", \"CLEAN_output\", \"EXTRACT_output\"):\n",
    "            if k in x and isinstance(x[k], str):\n",
    "                return x[k]\n",
    "        return json.dumps(x, ensure_ascii=False)\n",
    "    return str(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4750ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON Parser:\n",
    "'''This function try to parse the JSON object from string'''\n",
    "\n",
    "def parser_json_safe(raw):\n",
    "    \"\"\"Parse JSON robustly. Accepts dict or str; falls back to substring.\"\"\"\n",
    "    if isinstance(raw, dict):\n",
    "        return raw\n",
    "    if not isinstance(raw, str):\n",
    "        return {\"__raw__\": raw}\n",
    "    try:\n",
    "        return json.loads(raw)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        s, e = raw.find(\"{\"), raw.rfind(\"}\") # s: index of \"{\" and e: index of \"}\"\n",
    "        if s != -1 and e != -1 and e > s:\n",
    "            return json.loads(raw[s:e+1])\n",
    "    except Exception:\n",
    "        pass\n",
    "    return {\"__raw__\": raw}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa085cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _heuristic_extract(clean_text: str) -> dict:\n",
    "    \"\"\"Very simple regex-based extractor to keep DB flowing when AI is down.\"\"\"\n",
    "    def find(pat, s):\n",
    "        m = re.search(pat, s, re.IGNORECASE)\n",
    "        return m.group(1).strip() if m else None\n",
    "\n",
    "    vendor = find(r\"Vendor:\\s*(.+)\", clean_text)\n",
    "    number = find(r\"(?:Invoice Number|Invoice No\\.?):\\s*([A-Za-z0-9\\-]+)\", clean_text)\n",
    "    date   = find(r\"(?:Invoice Date|Date):\\s*([0-9]{4}-[0-9]{2}-[0-9]{2})\", clean_text)\n",
    "    total  = find(r\"Total:\\s*([0-9]+(?:\\.[0-9]+)?)\", clean_text)\n",
    "    curr   = find(r\"Total:\\s*[0-9]+(?:\\.[0-9]+)?\\s*([A-Za-z]{3})\", clean_text) or find(r\"Currency:\\s*([A-Za-z]{3})\", clean_text)\n",
    "\n",
    "    try: total = float(total) if total is not None else None\n",
    "    except: total = None\n",
    "\n",
    "    return {\n",
    "        \"vendor\": vendor,\n",
    "        \"number\": number,\n",
    "        \"date\":   date,\n",
    "        \"total\":  total,\n",
    "        \"currency\": curr,\n",
    "        \"line_items\": []\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57ded400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create OCR Node\n",
    "\n",
    "def NODE_OCR(file_path: str) -> Dict[str, Any]:\n",
    "    \"\"\"Read an Image file and return OCR text\"\"\"\n",
    "    text = \"\\n\".join(ocr.readtext(file_path, detail=0))\n",
    "    return {\"ocr_text\": text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2732b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Once we get OCR text then we call clean node with falback'''\n",
    "\n",
    "def NODE_CLEAN(ocr_text: str) -> Dict[str, Any]:\n",
    "    '''Normalize noisy OCR text using the CLEAN AI Node; fallback to pass-through on error'''\n",
    "    try:\n",
    "        clean_raw = clean_graph.run({\"ocr_text\": ocr_text})\n",
    "        clean_text = pick_text(clean_raw, prefer_key=\"CLEAN_output\")\n",
    "        if not isinstance(clean_text, str) or not clean_text.strip():\n",
    "            raise RuntimeError(\"Empty CLEAN output\")\n",
    "        return {\"clean_text\": clean_text, \"CLEAN_raw\": clean_raw}\n",
    "    except Exception as e:\n",
    "        print(f\"[CLEAN:FALLBACK] {e}\")\n",
    "        return {\"clean_text\": ocr_text, \"CLEAN_raw\": {\"fallback\": True}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d3d2b750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NODE_EXTRACT(clean_text_any) -> dict:\n",
    "    \"\"\"Extract structured JSON using the EXTRACT AI node; fallback to heuristic on error.\"\"\"\n",
    "    clean_text = pick_text(clean_text_any, prefer_key=\"CLEAN_output\")\n",
    "    try:\n",
    "        result = extract_graph.run({\"clean_text\": clean_text})\n",
    "        raw_json = pick_text(result, prefer_key=\"EXTRACT_output\")\n",
    "        return {\"raw_json\": raw_json, \"EXTRACT_raw\": result}\n",
    "    except Exception as e:\n",
    "        print(f\"[EXTRACT:FALLBACK] {e}\")\n",
    "        heuristic = _heuristic_extract(clean_text)\n",
    "        return {\"raw_json\": json.dumps(heuristic, ensure_ascii=False), \"EXTRACT_raw\": {\"fallback\": True}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f001116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''A validation node ensure that the data has the expected structure and values focusing on a few specific keys and their properties'''\n",
    "\n",
    "def NODE_VALIDATION(data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    '''Minimal schema checks and numeric sanity for demo purpose'''\n",
    "    issues: List[str] = [] # A list of error messages describing any problems\n",
    "    for k in [\"vendor\", \"number\", \"date\", \"currency\"]:\n",
    "        if k not in data or data.get(k) in (None, \"\"):\n",
    "            issues.append(f\"missing key: {k}\")\n",
    "    try:\n",
    "        if data.get(\"total\") is None:\n",
    "            issues.append(\"total is null\")\n",
    "        else:\n",
    "            float(data.get(\"total\"))\n",
    "    except Exception:\n",
    "        issues.append(f\"total not numeric: {data.get('total')}\")\n",
    "    if not isinstance(data.get(\"line_items\", []), list):\n",
    "        issues.append(\"line_items not a list\")\n",
    "    return {\"valid\": len(issues) == 0, \"issues\": issues}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ada12a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Persist Node: to store the data in database\n",
    "\n",
    "def NODE_PERSIST(file_name:str, data: dict, raw_json_any):\n",
    "    raw_json_str = json.dumps(raw_json_any, ensure_ascii=False) if not isinstance(raw_json_any, str) else raw_json_any\n",
    "    con = sqlite3.connect(DB_PATH)\n",
    "    cur = con.cursor()\n",
    "    cur.execute(\n",
    "        \"\"\"\n",
    "INSERT INTO invoices(file_name, vendor, number, date, total, currency, raw_json)\n",
    "VALUES (?, ?, ?, ?, ?, ?, ?)\"\"\",\n",
    "(\n",
    "    file_name,\n",
    "    data.get(\"vendor\"),\n",
    "    data.get(\"number\"),\n",
    "    data.get(\"date\"),\n",
    "    data.get(\"total\"),\n",
    "    data.get(\"currency\"),\n",
    "    raw_json_str,\n",
    "),\n",
    "    )\n",
    "    rowid = cur.lastrowid\n",
    "    con.commit()\n",
    "    con.close()\n",
    "    print(f\"[DB] Inserted row id={rowid} at {os.path.abspath(DB_PATH)}\")\n",
    "    return {\"db\": \"sqlite\", \"rowid\": rowid}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a0c4c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Notify Node: it send me the notifications.\n",
    "\n",
    "def NODE_NOTIFY(file_name:str, data:Dict[str, Any], valid:bool, issues:List[str]) -> None:\n",
    "    status = \"OK\" if valid else f\"WARN: {issues}\"\n",
    "    print(\n",
    "        f\"[{status}] file='{file_name}' vendor = {data.get(\"vendor\")} number = {data.get(\"number\")} total={data.get(\"total\")} {data.get(\"currency\")}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ca70d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Nodes\n",
    "NODES = [\"WATCH\", \"OCR\", \"CLEAN\", \"EXTRACT\", \"VALIDATE\", \"PERSIST\", \"NOTIFY\"]\n",
    "\n",
    "# Connecting nodes\n",
    "EDGES = [\n",
    "    (\"WATCH\", \"OCR\"),\n",
    "    (\"OCR\", \"CLEAN\"),\n",
    "    (\"CLEAN\", \"EXTRACT\"),\n",
    "    (\"EXTRACT\", \"VALIDATE\"),\n",
    "    (\"VALIDATE\", \"PERSIST\"),\n",
    "    (\"PERSIST\", \"NOTIFY\"),\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed696bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline_for_file(file_path: str) -> None:\n",
    "    file_name = os.path.basename(file_path)\n",
    "\n",
    "    # OCR → CLEAN → EXTRACT\n",
    "    ocr_out     = NODE_OCR(file_path)\n",
    "    clean_out   = NODE_CLEAN(pick_text(ocr_out.get(\"ocr_text\")))\n",
    "    extract_out = NODE_EXTRACT(clean_out.get(\"clean_text\"))\n",
    "\n",
    "    # Parse JSON → VALIDATE\n",
    "    raw_json = extract_out[\"raw_json\"]\n",
    "    data     = parser_json_safe(raw_json)\n",
    "    val_out  = NODE_VALIDATION(data)\n",
    "\n",
    "    # Persist + Notify\n",
    "    NODE_PERSIST(file_name, data, raw_json)\n",
    "    NODE_NOTIFY(file_name, data, val_out[\"valid\"], val_out[\"issues\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5fd419c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Watching 'invoices' every 5s. Only NEW .png/.jpg will be processed.\n",
      "Stopped watching.\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nWatching '{INPUT_DIR}' every {POLL_SEC}s. Only NEW .png/.jpg will be processed.\")\n",
    "try:\n",
    "    while True:\n",
    "        for fname in sorted(os.listdir(INPUT_DIR)):\n",
    "            if not fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                continue\n",
    "            if fname in seen:\n",
    "                continue  # already processed (persists across restarts)\n",
    "            fpath = os.path.join(INPUT_DIR, fname)\n",
    "            try:\n",
    "                run_pipeline_for_file(fpath)          # trigger full pipeline\n",
    "                seen.add(fname); save_seen(seen)      # mark as processed\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] {fname}: {e}\")\n",
    "        time.sleep(POLL_SEC)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopped watching.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "invoice-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
